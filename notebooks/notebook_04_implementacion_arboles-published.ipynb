{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/aprendizaje-automatico-dc-uba-ar/material/blob/main/notebooks/notebook_04_implementacion_arboles-published.ipynb)\n", "\n", "## \u00c1rboles de decisi\u00f3n\n", "\n", "### Metiendonos debajo del capot\n", "\n", "En esta notebook exploraremos el funcionamiento de un \u00e1rbol de decisi\u00f3n construido aqu\u00ed mismo.\n", "\n", "Para eso contaremos con algunas partes de c\u00f3digo resueltas y otras que se deber\u00e1n completar.\n", "\n", "El objetivo ser\u00e1 comprender la esencia de c\u00f3mo se comportan los \u00e1rboles a medida que le vamos agregando funcionalidad (o introduciendo _bugs_) para entender mejor su funcionamiento."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Puede ser necesario instalar graphviz\n", "#!pip install graphviz"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Cargamos bibliotecas necesarias\n", "import numpy as np\n", "import pandas as pd\n", "\n", "from collections import Counter\n", "import operator # Trae los operadores de Python como funciones y no infix\n", "from IPython.display import Image, display\n", "\n", "from graphviz import Digraph\n", "import pydotplus"]}, {"cell_type": "markdown", "metadata": {}, "source": ["A lo largo de esta notebook usaremos objetos de distintos tipos de datos. Por simplicidad diremos que en todos los casos asumiremos que los par\u00e1metros pasados para cada funci\u00f3n ser\u00e1n de los siguientes tipos:\n", "\n", "   - el par\u00e1metro `instancias` ser\u00e1 un `DataFrame` de `pandas`\n", "   - el par\u00e1metro `etiquetas` ser\u00e1 un `array` de `numpy` con valores `'Si'`, `'No'` (mismo para `etiquetas_rama_izquierda` y `etiquetas_rama_derecha`)\n", "   - el par\u00e1metro `pregunta` ser\u00e1 un objeto de la clase `Decision` que es definida en este mismo archivo\n", "\n", "\n", "La clase \u00c1rbol que definiremos a continuaci\u00f3n, consta de:\n", "\n", "   - un constructor\n", "   - el m\u00e9todo `fit` para entrenarlo (a modo de sklearn)\n", "   - el m\u00e9todo `predict` para dada una instancia predecir su etiqueta\n", "   - el m\u00e9todo `score` no se encuentra implementar a\u00fan\n", "   - m\u00e9todos para visualizar y explorar el \u00e1rbol\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Definici\u00f3n de la clase \u00e1rbol\n", "from typing import Optional, Tuple\n", "\n", "\n", "class Tree:\n", "    def __init__(\n", "        self,\n", "        decision=None,  # Esto va a tener tipo Decision, una clase que vamos a definir m\u00e1s adelante\n", "        left: Optional[\"Tree\"] = None,\n", "        right: Optional[\"Tree\"] = None,\n", "        labels: Optional[np.ndarray] = None,\n", "    ):\n", "        self.decision = decision\n", "        self.left = left\n", "        self.right = right\n", "\n", "        self.data = Counter(labels) if labels is not None else None\n", "\n", "    def fit(self, instancias: pd.DataFrame, etiquetas: np.ndarray):\n", "        # ALGORITMO RECURSIVO para construcci\u00f3n de un \u00e1rbol de decisi\u00f3n binario.\n", "\n", "        # Suponemos que estamos parados en la raiz del \u00e1rbol y tenemos que decidir c\u00f3mo construirlo.\n", "        gain, decision = encontrar_mejor_atributo_y_corte(instancias, etiquetas)\n", "\n", "        # Criterio de corte: \u00bfHay ganancia?\n", "        if gain <= 0:\n", "            #  Si no hay ganancia en separar, no separamos.\n", "            self.data = Counter(etiquetas)\n", "        else:\n", "            # Si hay ganancia en partir el conjunto en 2\n", "            (\n", "                instancias_cumplen,\n", "                etiquetas_cumplen,\n", "                instancias_no_cumplen,\n", "                etiquetas_no_cumplen,\n", "            ) = partir_segun(decision, instancias, etiquetas)\n", "            # partir devuelve instancias y etiquetas que caen en cada rama (izquierda y derecha)\n", "\n", "            # Paso recursivo (consultar con el computadorX m\u00e1s cercano)\n", "            sub_arbol_izquierdo = Tree()\n", "            sub_arbol_izquierdo.fit(instancias_cumplen, etiquetas_cumplen)\n", "            sub_arbol_derecho = Tree()\n", "            sub_arbol_derecho.fit(instancias_no_cumplen, etiquetas_no_cumplen)\n", "            # los pasos anteriores crean todo lo que necesitemos de sub-\u00e1rbol izquierdo y sub-\u00e1rbol derecho\n", "\n", "            self.decision = decision\n", "            self.left = sub_arbol_izquierdo\n", "            self.right = sub_arbol_derecho\n", "            self.data = Counter(etiquetas)\n", "\n", "    def predict(self, x_t: pd.Series) -> str:\n", "        if self.decision is None:\n", "            if self.data[\"positive\"] > self.data[\"negative\"]:\n", "                return \"positive\"\n", "            else:\n", "                return \"negative\"\n", "        else:\n", "            if self.decision.test(x_t):\n", "                return self.left.predict(x_t)\n", "            else:\n", "                return self.right.predict(x_t)\n", "\n", "    def score(self, X_test: pd.DataFrame, y_test: np.ndarray) -> float:\n", "        # COMPLETAR\n", "        pass\n", "\n", "    def __repr__(self) -> str:\n", "        return self._imprimir_arbol()\n", "\n", "    def _imprimir_arbol(self, spacing: str = \"\") -> str:\n", "        res = []\n", "        if self.decision is None:\n", "            res.append(spacing + f\"Hoja: {dict(self.data)}\")\n", "        else:\n", "            res.append(spacing + f\"{str(self.decision)} - {dict(self.data)}\")\n", "\n", "        if self.left is not None:\n", "            res.append(spacing + \"--> True:\")\n", "            res.append(self.left._imprimir_arbol(spacing + \"  \"))\n", "\n", "        if self.right is not None:\n", "            res.append(spacing + \"--> False:\")\n", "            res.append(self.right._imprimir_arbol(spacing + \"  \"))\n", "\n", "        return \"\\n\".join(res)\n", "\n", "    def render(self) -> Digraph:\n", "        dot = Digraph()\n", "\n", "        self.dot_tree_aux(self, dot, prefix=\"\")\n", "\n", "        return dot\n", "\n", "    def dot_tree_aux(self, subtree: \"Tree\", dot: Digraph, prefix: str):\n", "        label = [\n", "            (\n", "                f\"{subtree.decision.feature}: {subtree.decision.value}\"\n", "                if subtree.decision is not None\n", "                else \"\"\n", "            ),\n", "            f\"n={sum(subtree.data.values())}\",\n", "            str(dict(subtree.data)),\n", "        ]\n", "        label = \"\\n\".join(label)\n", "        col = \"#029E3980\" if subtree.data.most_common(1)[0][0] == \"Si\" else \"#EA080080\"\n", "        dot.node(prefix + \"n\", label=label, shape=\"box\", fillcolor=col, style=\"filled\")\n", "\n", "        if subtree.left:\n", "            self.dot_tree_aux(subtree.left, dot, prefix + \"l\")\n", "            dot.edge(prefix + \"n\", prefix + \"ln\", label=\"True\")\n", "\n", "        if subtree.right:\n", "            self.dot_tree_aux(subtree.right, dot, prefix + \"r\")\n", "            dot.edge(prefix + \"n\", prefix + \"rn\", label=\"False\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Para la decisiones en cada nodo tendremos la siguiente clase. Actualmente funciona comparando por igualdad, pero podr\u00eda ser extendida en el futuro."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from typing import Any\n", "\n", "class Decision:\n", "    def __init__(self, feature: str, value: Any, test_function=operator.eq):\n", "        self.feature = feature\n", "        self.value = value\n", "        self.test_function = test_function\n", "\n", "    def test(self, x: pd.Series) -> bool:\n", "        # Devuelve verdadero si la instancia cumple con la pregunta\n", "        return self.test_function(self.value, x[self.feature])\n", "\n", "    def __repr__(self):\n", "        return \"\u00bfEs el valor para {} igual a {}?\".format(self.feature, self.value)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Funciones a completar\n", "\n", "Primero definir la funci\u00f3n `gini`, que dado unas etiquetas dan el grado de impureza (ver definici\u00f3n en la te\u00f3rica), se espera que devuelva un `float`."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def gini(etiquetas: np.ndarray) -> float:\n", "    # COMPLETAR\n", "    impureza = 0\n", "    return impureza"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Definir la funci\u00f3n `ganancia_gini` que dadas ciertas instancias y una posible separaci\u00f3n entre dos ramas nos de la mejora que obtendremos al separar de esta manera. Devuelve un `float`."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def ganancia_gini(etiquetas_rama_izquierda: np.ndarray, etiquetas_rama_derecha: np.ndarray) -> float:\n", "    # COMPLETAR\n", "    ganancia_gini = 0\n", "    return ganancia_gini"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Definir `partir_segun` que debe separar instancias y etiquetas seg\u00fan si cada instancia cumple o no con condici\u00f3n (ver m\u00e9todo `test` de la clase `Decision`).\n", "\n", "Para este punto se recomienda la utilizacion de m\u00e1scaras de pandas (ver Notebook 01 - Herramientas).\n", "\n", "Siguiendo con lo mencionado al inicio del NoteBook, la funci\u00f3n debe devolver:\n", "\n", "   - 2 `DataFrame` de `pandas` con las instancias que cumplen (`instancias_cumplen`) y las que no `instancias_no_cumplen`\n", "   - 2 `array` de `numpy` con valores `'Si'`, `'No'`, uno con el valor de la etiqueta para las intancias que cumplen con la pregunta (`etiquetas_cumplen`) y otro con las etiquetas de las que no cumple (`etiquetas_cumplen`)\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def partir_segun(\n", "    pregunta: Decision, \n", "    instancias: pd.DataFrame, \n", "    etiquetas: np.ndarray\n", ") -> Tuple[pd.DataFrame, np.ndarray, pd.DataFrame, np.ndarray]:\n", "    # Esta funci\u00f3n debe separar instancias y etiquetas seg\u00fan si cada instancia cumple o no\n", "    # COMPLETAR\n", "    (instancias_cumplen,\n", "         etiquetas_cumplen,\n", "         instancias_no_cumplen,\n", "         etiquetas_no_cumplen) = [], [], [], []\n", "\n", "    return instancias_cumplen, etiquetas_cumplen, instancias_no_cumplen, etiquetas_no_cumplen"]}, {"cell_type": "markdown", "metadata": {}, "source": ["A continuaci\u00f3n se propone una implementaci\u00f3n para poder encontrar el mejor atributo y corte posible. Esta funci\u00f3n devuelve un `float` y una `Decision` correspondientes al mejor atributo y corte."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def encontrar_mejor_atributo_y_corte(\n", "    instancias: pd.DataFrame, etiquetas: np.ndarray\n", ") -> Tuple[float, Decision]:\n", "    # Implementaci\u00f3n Gini Gain.\n", "    max_ganancia = 0\n", "    mejor_pregunta = None\n", "    for columna in instancias.columns:\n", "        for valor in set(instancias[columna]):\n", "            # Probando corte para atributo y valor\n", "            pregunta = Decision(columna, valor)\n", "            _, etiquetas_rama_izquierda, _, etiquetas_rama_derecha = partir_segun(\n", "                pregunta, instancias, etiquetas\n", "            )\n", "            if len(etiquetas_rama_izquierda) == 0 or len(etiquetas_rama_derecha) == 0:\n", "                continue\n", "\n", "            ganancia = ganancia_gini(etiquetas_rama_izquierda, etiquetas_rama_derecha)\n", "\n", "            if ganancia > max_ganancia:\n", "                max_ganancia = ganancia\n", "                mejor_pregunta = pregunta\n", "\n", "    return max_ganancia, mejor_pregunta"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Dado el siguiente dataset:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.datasets import fetch_openml\n", "import sklearn.model_selection\n", "\n", "tictactoe = fetch_openml(name='tic-tac-toe', version=1, as_frame=True)\n", "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(\n", "                    tictactoe['data'], \n", "                    tictactoe['target'], \n", "                    random_state=4, \n", "                    test_size=0.1)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Completar las funciones previas, entrenar y visualizar un \u00c1rbol de Decisi\u00f3n."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["arbol = Tree()\n", "arbol.fit(X_train, y_train)\n", "print(arbol)\n", "arbol.render()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Para evaluar instancias en el \u00e1rbol podemos elegir alguna del conjunto de testeo y evaluarlas de la siguiente manera:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["xs_nuevo = X_test.head(4).to_dict(orient='records')\n", "\n", "for instancia in xs_nuevo:\n", "    res = arbol.predict(instancia)\n", "    print(f\"Para una instancia {instancia} obtuve {res}\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\u00bfSe obtuvieron los valores esperados? Explorar al menos 1 caso por cada rama del \u00e1rbol."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Importancia de los atributos"]}, {"cell_type": "markdown", "metadata": {}, "source": ["A continuaci\u00f3n, implementaremos dos m\u00e9todos distintos para medir la importancia de los atributos en nuestro \u00e1rbol de decisi\u00f3n. Estos m\u00e9todos nos permitir\u00e1n entender mejor qu\u00e9 variables tienen mayor influencia en las predicciones del modelo. El primer m\u00e9todo que implementaremos es la Importancia Gini, que se basa en la reducci\u00f3n de la impureza Gini en cada nodo del \u00e1rbol. El segundo m\u00e9todo es la Importancia por Permutaci\u00f3n, que eval\u00faa cu\u00e1nto empeora el rendimiento del modelo cuando los valores de una caracter\u00edstica se permutan aleatoriamente."]}, {"cell_type": "markdown", "metadata": {}, "source": ["*Gini importance*"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def gini_importance(tree: Tree) -> dict:\n", "    \"\"\"\n", "    Calcula la Disminuci\u00f3n Media en la Impureza (Importancia Gini) para un \u00e1rbol de decisi\u00f3n entrenado.\n", "\n", "    Argumentos:\n", "    - arbol: Una instancia de Tree entrenada\n", "\n", "    Retorna:\n", "    - Un diccionario que asocia los nombres de los atributos con sus puntajes de importancia Gini\n", "    \"\"\"\n", "    \n", "    importance = {}\n", "    \n", "    def recorrer_arbol(node: Tree, parent_samples: int):\n", "        # Si es una hoja termina la recursi\u00f3n\n", "        if node.decision is None:  \n", "            return\n", "        \n", "        # Qu\u00e9 atributo se uso en ese nodo\n", "        feature = node.decision.feature \n", "        \n", "        # Si todavia no habiamos usado ese atributo para partir un nodo\n", "        if feature not in importance:\n", "            importance[feature] = 0\n", "        \n", "        # Calculamos Gini gain del corte\n", "        gini_gain = #COMPLETAR\n", "        \n", "        \n", "        # Actualizamos el valor de ese atributo\n", "        importance[feature] = #COMPLETAR\n", "        \n", "        # Recorrer recursivamente los sub\u00e1rboles\n", "        recorrer_arbol(node.left, parent_samples)\n", "        recorrer_arbol(node.right, parent_samples)\n", "    \n", "    # Arrancamos el recorrido desde la ra\u00edz\n", "    cantidad_total = sum(tree.data.values())\n", "    recorrer_arbol(tree, cantidad_total)\n", "    \n", "    return importance"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["gini_importance(arbol)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["*Permutation importance*"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from typing import Callable\n", "\n", "def permutation_importance(\n", "    tree: Tree,\n", "    X: pd.DataFrame,\n", "    y: np.ndarray,\n", "    score_func: Callable,\n", "    n_repeats: int = 10\n", ") -> dict:\n", "    \"\"\"\n", "    Calcula la importancia por permutaci\u00f3n para los atributos en un \u00e1rbol entrenado.\n", "\n", "    Argumentos:\n", "    - tree: Instancia de Tree entrenada\n", "    - X: DataFrame de atributos\n", "    - y: Vector de etiquetas \n", "    - score_func: Funci\u00f3n para calcular el puntaje (por ejemplo, accuracy_score, r2_score)\n", "    - n_repeats: N\u00famero de veces para repetir el proceso de permutaci\u00f3n\n", "\n", "    Retorna:\n", "    - Diccionario de importancias de los atributos\n", "    \"\"\"\n", "    \n", "    # Calcular el puntaje de referencia\n", "    y_pred = np.array([tree.predict(x) for _, x in X.iterrows()])\n", "    reference_score = score_func(y, y_pred)\n", "    \n", "    n_samples, n_features = X.shape\n", "    importances = {}\n", "\n", "    for feature in X.columns:\n", "        feature_importance = []\n", "        \n", "        for _ in range(n_repeats):\n", "            # Crear una copia de los datos\n", "            X_corrupted = #COMPLETAR\n", "            \n", "            # Permutar aleatoriamente los valores en la columna feature\n", "            X_corrupted[feature] = #COMPLETAR\n", "            \n", "            # Calcular el nuevo score usando los datos corrompidos\n", "            corrupted_score = #COMPLETAR\n", "            \n", "            feature_importance.append(corrupted_score)\n", "        \n", "        # Calcular la importancia para este atributo seg\u00fan el algoritmo\n", "        importances[feature] = #COMPLETAR\n", "\n", "    return importances"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.metrics import accuracy_score\n", "\n", "permutation_importance(arbol, X_train, y_train, accuracy_score)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\u00bfSe obtienen los mismos valores cuando se calcula sobre el conjunto de testeo?"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Opcional: Atributos continuos"]}, {"cell_type": "markdown", "metadata": {}, "source": ["La implementaci\u00f3n anterior permite construir \u00e1rboles partiendo de un dataset cuyos atributos no son continuos. Modificar dicha implementaci\u00f3n para que soporte este tipo de atributos.\n", "\u00bfQu\u00e9 funciones hay que modificar? "]}], "metadata": {"celltoolbar": "Tags", "kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.10.12"}}, "nbformat": 4, "nbformat_minor": 2}