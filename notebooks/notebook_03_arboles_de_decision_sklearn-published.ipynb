{"cells": [{"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/aprendizaje-automatico-dc-uba-ar/material/blob/main/notebooks/notebook_03_arboles_de_decision_sklearn-published.ipynb)\n", "\n", "## Scikit-learn (sklearn)\n", "\n", "### Primera aplicaci\u00f3n, clasificaci\u00f3n de \"iris\"\n", "\n", "El dataset Fisher's Iris es un conjunto de datos multivariado introducido por Ronald Fisher en su paper de 1936 *The use of multiple measurements in taxonomic problems* como un ejemplo de an\u00e1lisis discriminante lineal.\n", "\n", "\n", "![Representaci\u00f3n de las flores del data set](https://github.com/aprendizaje-automatico-dc-uba-ar/material/raw/main/notebooks/n03-iris.png)\n", "\n", "\n", "\n", "El conjunto de datos contiene 50 muestras de cada una de tres especies de Iris (Iris setosa, Iris virginica e Iris versicolor). Se midi\u00f3 cuatro rasgos de cada muestra: el largo y ancho del s\u00e9palo y p\u00e9talo, en cent\u00edmetros y adem\u00e1s se tiene el nombre de la especie a la que pertence. Basado en la combinaci\u00f3n de estos cuatro rasgos, Fisher desarroll\u00f3 un modelo discriminante lineal para distinguir entre una especie y otra."]}, {"cell_type": "markdown", "metadata": {}, "source": ["Antes de empezar, cargamos todas las bibliotecas que vamos a usar. Como iris es un dataset muy com\u00fan, forma parte de los datasets que provee `sklearn`.\n", "\n", "\n", "Ac\u00e1 vemos como cargarlo:"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# Cargamos algunas bibliotecas \n", "import numpy as np\n", "import pandas as pd\n", "import sklearn \n", "import matplotlib.pyplot as plt\n", "plt.rcParams['figure.figsize'] = [10, 5] # para ver los gr\u00e1ficos m\u00e1s grandes\n", "\n", "# Cargamos el dataset que usaremos hoy\n", "from sklearn.datasets import load_iris\n", "iris_dataset = load_iris()"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "fragment"}}, "source": ["### Antes de empezar: exploraci\u00f3n del objeto ```iris_dataset```\n", "\n", "1. \u00bfQu\u00e9 tipo de objeto es `iris_dataset`?\n", "1. Listar las claves que tiene.\n", "1. Listar los valores que puede tomar la variable `target` (las que vamos a querer aprender).\n", "1. Listar los atributos del dataset.\n", "1. \u00bfQu\u00e9 hay en las primeras 5 filas?\n", "1. \u00bfQu\u00e9 dimensi\u00f3n tiene el dataset?\n", "1. \u00bfCu\u00e1l es el `target` en las \u00faltimas 5 filas?\n", "\n", "Adem\u00e1s, hay una descripci\u00f3n del dataset incluida en el objeto que se puede acceder con: `iris_dataset.DESCR`.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["### Paso 1: Divisi\u00f3n de datos (training - testing)\n", "\n", "Ya veremos en las pr\u00f3ximas clases de la materia, pero una forma de mitigar la percepci\u00f3n de cu\u00e1n bien (o mal) anda nuestro modelo, es separar nuestros datos en 2:\n", "\n", "  - una parte para mirar, entender y **entrenar**\n", "  - otra parte que solo usaremos para medir la performance\n", "\n", "(m\u00e1s detalles en breve)\n", "\n", "<img src=\"https://github.com/aprendizaje-automatico-dc-uba-ar/material/raw/main/notebooks/n03-train-test-split.png\"  width=\"600\">\n", "Fuente imagen: https://www.sharpsightlabs.com/blog/scikit-train_test_split/\n", "\n", "\n", "Para esto usaremos la funci\u00f3n `train_test_split` de `sklearn` [(ver Documentaci\u00f3n)](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) y generaremos:\n", "  - `X_train`: es una matriz con un subconjunto del dataset original con los atributos de las observaciones \n", "  - `y_train`: es un vector con la clase a la que corresponde cada instancia de `X_train` \n", "  - `X_test`: es el subconjunto restante del dataset original que no fue incluido en `X_train`\n", "  - `y_test`: es un vector con la clase a la que corresponde cada instancia de `X_test` "]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "fragment"}}, "outputs": [], "source": ["import sklearn.model_selection\n", "\n", "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(\n", "                    iris_dataset['data'], \n", "                    iris_dataset['target'], \n", "                    random_state=4, \n", "                    test_size=0.1)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Podemos verificar que los tama\u00f1os para ver que coinciden con lo previsto. Sugerencia: explorar los objetos."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(f\"X_train dimensi\u00f3n: {X_train.shape}\")\n", "print(f\"y_train dimensi\u00f3n: {y_train.shape}\")\n", "\n", "print(f\"X_test dimensi\u00f3n: {X_test.shape}\")\n", "print(f\"y_test dimensi\u00f3n: {y_test.shape}\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Pregunta** \n", "\n", "\u00bfQu\u00e9 orden tienen los datos en esta partici\u00f3n? \u00bfPreservan el mismo orden? *Hint* Ver documentaci\u00f3n de `train_test_split`"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["### Paso 2: Exploraci\u00f3n de los datos\n", "\n", "Como vimos anteriormente, los datos se encuentran dentro de un _array_ de `numpy`. Podemos pasarlo a un dataframe de `pandas` para tener una mejor visualizaci\u00f3n.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "fragment"}}, "outputs": [], "source": ["iris_dataframe = pd.DataFrame(X_train, columns=iris_dataset.feature_names)\n", "iris_dataframe.head(10)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Antes de empezar a construir un clasificador, realicemos una breve exploraci\u00f3n de los datos:\n", "\n", "1. \u00bfqu\u00e9 se ve en el siguiente gr\u00e1fico?\n", "1. \u00bfcu\u00e1ntas clases hay?\n", "1. \u00bfqu\u00e9 variable (o pares de variables) parecen separar mejor a los datos?\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["y_train"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "fragment"}}, "outputs": [], "source": ["pd.plotting.scatter_matrix(iris_dataframe, c=y_train, s=80, figsize=(15, 8), alpha=.8);"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["### Paso 3: Construcci\u00f3n de un modelo \n", "\n", "Para construir nuestro \u00e1rbol creamos un objeto de la clase [`DecisionTreeClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) a la que m\u00e1s tarde cambiaremos par\u00e1metros.\n", "\n", "En este punto definimos que:\n", "  - la profundidad m\u00e1xima del \u00e1rbol ser\u00e1 3\n", "  - que el criterio para la selecci\u00f3n en cada nodo sera `entropy`\n", "  \n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.tree import DecisionTreeClassifier\n", "arbol = DecisionTreeClassifier(max_depth=3, criterion=\"entropy\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Una vez creado nuestro clasificador, debemos entrenarlo con el m\u00e9todo `fit`. \n", "\n", "Es interesante mencionar que en `sklearn` siempre usaremos `fit()` para entrenar pasandole los datos. La configuraci\u00f3n vendr\u00e1 en el constructor.\n", "\n", "**Antes** de ejecutar `fit` explorar `arbol.fit?`."]}, {"cell_type": "code", "metadata": {}, "source": ["arbol.fit?"], "outputs": [], "execution_count": null}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "fragment"}}, "outputs": [], "source": ["arbol.fit(X_train, y_train)"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["### Paso 4: Predicciones\n", "\n", "Si queremos predecir una nueva instancia, por ejemplo:"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "fragment"}}, "outputs": [], "source": ["X_new = np.array([[5, 2.9, 1, 0.2]])\n", "print(f\"X_new.shape: {X_new.shape}\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Necesitamos contar con nuestro clasificador (previamente entrenado) e invocar a `predict` con la(s) instancia(s) que queremos predecir.\n", "\n", "**Antes** de ejecutar `predict` explorar `arbol.predict?`."]}, {"cell_type": "code", "metadata": {}, "source": ["arbol.predict?"], "outputs": [], "execution_count": null}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "fragment"}}, "outputs": [], "source": ["prediction = arbol.predict(X_new)\n", "print(f\"Predicci\u00f3n: {prediction}\")\n", "print(f\"Nombre de la clase predicha: {iris_dataset['target_names'][prediction]}\")"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["### Paso 5: Evaluaci\u00f3n del modelo\n", "\n", "Ahora ya estamos listos para poder verificar la performance de nuestro \u00e1rbol con los datos que hab\u00edamos separado para _test_ previamente."]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "fragment"}}, "outputs": [], "source": ["# predecimos los valores para las instacias que no vimos\n", "y_pred = arbol.predict(X_test)\n", "\n", "print(f\"Predicciones:   {y_pred}\\nValores reales: {y_test}\")\n", "# Podemos calcular el accuracy (exactitud) comparando los valores predichos contra los reales, \n", "# para ello contamos cu\u00e1ntas coincidencias hubo y dividimos por la cantidad de comparaciones que hicimos:\n", "print(f\"Accuracy sobre el test set: {np.mean(y_pred == y_test)}\") \n", "\n", "#Tambi\u00e9n podemos invocar al m\u00e9todo score que viene con los DecisionTreeClassifier\n", "print(f\"Accuracy sobre el test set: {arbol.score(X_test, y_test)}\") "]}, {"cell_type": "markdown", "metadata": {}, "source": ["Podemos observar el resultado de nuestra clasificaci\u00f3n con las matrices de confusi\u00f3n que tienen:\n", "- cada fila los valores observados o reales\n", "- cada columna los valores predichos\n", "\n", "que si integramos esta informaci\u00f3n nos da:\n", "- $m_{i,i}$ las instancias bien clasificadas\n", "- $m_{i,j}\\ (con\\ i\\neq j)$ las instancias mal clasificadas\n", "\n", "Ej. si tenemos la siguiente matriz de confusi\u00f3n:\n", "\n", "||setosa|versicolor|virginica|\n", "|-----|-----|-----|-----|\n", "|**setosa**| 6 | 0 | 0 |\n", "|**versicolor**| 0 | 2 | 1 |\n", "|**virginica**| 0 | 0 | 6 | \n", "\n", "Podemos decir que todas las instancias de la clases **setosa** y **virginica** fueron correctamente clasificadas, mientras que para las de **versicolor** 2 fueron correctas, mientras que una fue clasificada con **virginica** fallando en este caso la predicci\u00f3n.\n", "\n", "Si sumamos por filas podemos ver que en _test_ tenemos: \n", "  - 6 de clase **setosa**\n", "  - 3 de clase **versicolor** \n", "  - 6 de clase **virginica**\n", "  \n", "Y si sumamos por columna podemos ver la cantidad predicha para cada clase:\n", "  - 6 de clase **setosa**\n", "  - 2 de clase **versicolor** \n", "  - 7 de clase **virginica**\n", "  "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"Matriz de confusi\u00f3n:\")\n", "confusion = sklearn.metrics.confusion_matrix(y_pred=y_pred, y_true=y_test)\n", "display(pd.DataFrame(confusion, columns=iris_dataset['target_names'], index=iris_dataset['target_names']))"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["### En resumen\n", "\n", "1. separamos nuestro data set original en entrenamiento (_train_) y evaluaci\u00f3n (_test_)\n", "1. armamos y entrenamos (`fit`) un \u00e1rbol de decisi\u00f3n con par\u00e1metros:\n", "    - `max_depth=3`\n", "    - `criterion=\"entropy\"`\n", "1. evaluamos el \u00e1rbol en el conjunto de entrenamiento y de evaluaci\u00f3n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "fragment"}}, "outputs": [], "source": ["X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(\n", "    iris_dataset['data'], iris_dataset['target'], random_state=4, test_size=0.1)\n", "\n", "arbol = DecisionTreeClassifier(max_depth=3, criterion=\"entropy\")\n", "arbol.fit(X_train, y_train)\n", "\n", "print(f\"Score sobre el training set: {arbol.score(X_train, y_train):.2f} \u00bfqu\u00e9 indica este n\u00famero?\")\n", "print(f\"Score sobre el test set: {arbol.score(X_test, y_test):.2f}  \u00bfqu\u00e9 indica este n\u00famero?\")\n"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["### Experimentando con \u00c1rboles de Decisi\u00f3n: \n", "\n", "1. Probar distintos valores para: `max_depth` y graficar la performance (_accuracy_) sobre el conjunto de test al variar este par\u00e1metro. \n", "1. \u00bfQu\u00e9 ocurre con la _accuracy_ sobre train con respecto al valor sobre test de un mismo clasificador? \n", "1. \u00bfCu\u00e1l es el m\u00e1ximo valor de profundidad que se alcanza?\u00bfc\u00f3mo lo obtengo?\u00bfpor qu\u00e9? \n", "    Para responder estas pregunta se puede acceder a la documentaci\u00f3n con el comando `sklearn.tree.DecisionTreeClassifier?`\n", "1. Graficar la importancia de features para el clasificador con mejor _Accuracy_ en el test_set. Explorar el atributo `feature_importances_` de un \u00e1rbol entrenado, \u00bfqu\u00e9 atributos fueron los mas relevantes? \u00bfes el mismo m\u00e9todo que el visto en clase?\n", "1. Evaluar la importancia de features utilizando `permutation_importance`, graficar.\n", "    \n", "1. Graficar el \u00e1rbol obtenido (ver funci\u00f3n `dibujar_arbol` provista en la pr\u00f3xima celda). \n", "\n", "    1. \u00bfqu\u00e9 representa cada nodo?\n", "    1. \u00bfqu\u00e9 informaci\u00f3n contiene cada nodo?\n", "    1. \u00bfqu\u00e9 representa el color?\n", "    1. \u00bfqu\u00e9 son los ejes?"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "skip"}}, "outputs": [], "source": ["# !pip3 install pydotplus\n", "# Tambi\u00e9n instalar Graphviz. (en ubuntu: sudo apt-get install graphviz)\n", "\n", "from six import StringIO  #pip3 install six\n", "##### from sklearn.externals.six import StringIO  # opci\u00f3n para versiones m\u00e1s viejas de sklearn\n", "from IPython.display import Image, display\n", "import pydotplus\n", "\n", "    \n", "def dibujar_arbol(clf, c_name=iris_dataset.target_names, f_name=iris_dataset.feature_names):\n", "    #\n", "    # modo de uso: dibujar_arbol(arbol)\n", "    #\n", "    dot_data = StringIO()\n", "    sklearn.tree.export_graphviz(clf, out_file = dot_data,  \n", "                    filled = True, \n", "                    class_names = c_name,\n", "                    feature_names = f_name,\n", "                    special_characters = True)\n", "\n", "    graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n", "    display(Image(graph.create_png()))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Sobre fronteras de decisi\u00f3n\n", "\n", "A continuaci\u00f3n exploraremos dentro del dataset iris el funcionamiento de las fronteras de decisi\u00f3n.\n", "Para hacerlo nos quedaremos s\u00f3lo con 2 dimensiones del dataset: `sepal length (cm)`, `sepal width (cm)`.\n", "\n", "En la pr\u00f3xima celda tenemos la funci\u00f3n `explore_decision_tree_boundaries` que si es llamada sin par\u00e1metros corre un \u00e1rbol de clasificaci\u00f3n con los par\u00e1metros por defecto del mismo y genera una representaci\u00f3n de como el plano conformado por las 2 dimensiones propuesta se dividen en las clases que predecir\u00e1n y \u00e1rbol que gener\u00f3 dichas fronteras.\n", "\n", "Explorar diversos valores permitidos de profundidad m\u00e1xima permitido del \u00e1rbol del clasificador y analizar las visualizaciones generadas en t\u00e9rminos de: \n", "  - sobreajuste\n", "  - subajuste"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.inspection import DecisionBoundaryDisplay\n", "\n", "def explore_decision_tree_boundaries(max_depth=None, criterion=\"entropy\", data_set=iris_dataset, cols=[0, 1]):\n", "    n_classes, plot_colors, plot_step = 3, \"ryb\", 0.02\n", "    fig=plt.figure(figsize=(10,7), dpi= 100, facecolor='w', edgecolor='k')\n", "    \n", "    X = data_set[\"data\"][:, cols]\n", "    y = data_set[\"target\"]\n", "\n", "    # Build and train Classifier\n", "    tree = DecisionTreeClassifier(max_depth=max_depth, criterion=criterion).fit(X, y)\n", "\n", "    # Plot the decision boundary\n", "    ax = plt.subplot(1, 1, 1)\n", "    plt.tight_layout(h_pad=0.5, w_pad=0.5, pad=2.5)\n", "    DecisionBoundaryDisplay.from_estimator(\n", "        tree,\n", "        X,\n", "        cmap=plt.cm.RdYlBu,\n", "        response_method=\"predict\",\n", "        ax=ax,\n", "        xlabel=data_set.feature_names[cols[0]],\n", "        ylabel=data_set.feature_names[cols[1]],\n", "    )\n", "\n", "    # Plot the training points\n", "    for i, color in zip(range(n_classes), plot_colors):\n", "        idx = np.where(y == i)\n", "        plt.scatter(\n", "            X[idx, 0],\n", "            X[idx, 1],\n", "            c=color,\n", "            label=data_set.target_names[i],\n", "            cmap=plt.cm.RdYlBu,\n", "            edgecolor=\"black\",\n", "            s=15,\n", "        )\n", "\n", "    plt.suptitle(f\"Fronteras de decisi\u00f3n de un \u00e1rbol de altura {tree.get_depth()} y #hojas: {tree.get_n_leaves()}\")\n", "    plt.legend(loc=\"lower right\", borderpad=0, handletextpad=0)\n", "    _ = plt.axis(\"tight\")\n", "    plt.show()\n", "    \n", "    dibujar_arbol(tree, f_name=[data_set.feature_names[cols[0]],data_set.feature_names[cols[1]]]\n", "                 )\n", "    \n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Ejecutar la funci\u00f3n y luego explorar como cambia el comportamiento al modificar los par\u00e1metros por defecto:\n", "  - `max_depth`\n", "  - `criterion`"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["explore_decision_tree_boundaries()\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}], "metadata": {"celltoolbar": "Tags", "kernelspec": {"display_name": ".venv", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.10.12"}}, "nbformat": 4, "nbformat_minor": 2}